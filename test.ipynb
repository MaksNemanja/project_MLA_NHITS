{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.049671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.086107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.263634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.448110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.366372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     value\n",
       "0 2020-01-01  0.049671\n",
       "1 2020-01-02  0.086107\n",
       "2 2020-01-03  0.263634\n",
       "3 2020-01-04  0.448110\n",
       "4 2020-01-05  0.366372"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Créer des données artificielles pour la prévision de séries temporelles\n",
    "np.random.seed(42)\n",
    "\n",
    "n_timesteps = 1000  # Nombre total de timesteps\n",
    "date_range = pd.date_range(start=\"2020-01-01\", periods=n_timesteps, freq=\"D\")\n",
    "data = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'value': np.sin(np.linspace(0, 100, n_timesteps)) + np.random.normal(0, 0.1, n_timesteps)\n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'entrée (train_data[0]):\n",
      "X (backcast): [ 0.04967142  0.08610659  0.26363439  0.44811007  0.36637177  0.45645101\n",
      "  0.72305935  0.72149693  0.67096635  0.83814261  0.79566964  0.8451333\n",
      "  0.95666991  0.77257744  0.81319517  0.94137132  0.89824244  1.02286885\n",
      "  0.88263427  0.80445314  1.05502736  0.83956859  0.81395127  0.60169445\n",
      "  0.61925144  0.60755767  0.39817013  0.46250469  0.27228211  0.20726035\n",
      "  0.07797576  0.22370787 -0.0629213  -0.26677787 -0.17657553 -0.47614631\n",
      " -0.42486277 -0.72894062 -0.74768075 -0.67090876 -0.68556696 -0.80349252\n",
      " -0.88519405 -0.94799298 -1.10079866 -1.05045415 -1.04026076 -0.89425825\n",
      " -0.96137087 -1.15782999 -0.92508414 -0.96238124 -0.94869617 -0.76814699\n",
      " -0.66622249 -0.60850006 -0.71083098 -0.57683522 -0.42632688 -0.27083806]\n",
      "y (forecast): [-0.32156113 -0.1947211  -0.18753659 -0.09650172  0.2041621   0.35709357\n",
      "  0.31061132  0.51132656  0.53618328  0.51954808  0.69839259  0.88761939\n",
      "  0.79444912  1.01072246  0.6399574   1.02276614  0.97850784  0.9594203\n",
      "  1.00811026  0.79978944]\n",
      "X (backcast2): [ 0.08610659  0.26363439  0.44811007  0.36637177  0.45645101  0.72305935\n",
      "  0.72149693  0.67096635  0.83814261  0.79566964  0.8451333   0.95666991\n",
      "  0.77257744  0.81319517  0.94137132  0.89824244  1.02286885  0.88263427\n",
      "  0.80445314  1.05502736  0.83956859  0.81395127  0.60169445  0.61925144\n",
      "  0.60755767  0.39817013  0.46250469  0.27228211  0.20726035  0.07797576\n",
      "  0.22370787 -0.0629213  -0.26677787 -0.17657553 -0.47614631 -0.42486277\n",
      " -0.72894062 -0.74768075 -0.67090876 -0.68556696 -0.80349252 -0.88519405\n",
      " -0.94799298 -1.10079866 -1.05045415 -1.04026076 -0.89425825 -0.96137087\n",
      " -1.15782999 -0.92508414 -0.96238124 -0.94869617 -0.76814699 -0.66622249\n",
      " -0.60850006 -0.71083098 -0.57683522 -0.42632688 -0.27083806 -0.32156113]\n",
      "y (forecast2): [-0.1947211  -0.18753659 -0.09650172  0.2041621   0.35709357  0.31061132\n",
      "  0.51132656  0.53618328  0.51954808  0.69839259  0.88761939  0.79444912\n",
      "  1.01072246  0.6399574   1.02276614  0.97850784  0.9594203   1.00811026\n",
      "  0.79978944  0.96619418]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(data, max_encoder_length, max_prediction_length, test_size=0.1, validation_size=0.1):\n",
    "    \"\"\"\n",
    "    Crée un dataset avec des fenêtres glissantes pour backcast et forecast.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: DataFrame avec les données.\n",
    "    - max_encoder_length: Nombre de timesteps à utiliser pour le backcast (entrée).\n",
    "    - max_prediction_length: Nombre de timesteps à prédire (forecast).\n",
    "    - test_size: Proportion des données à utiliser pour l'ensemble de test.\n",
    "    - validation_size: Proportion des données à utiliser pour l'ensemble de validation.\n",
    "    \n",
    "    Returns:\n",
    "    - train_data, val_data, test_data: Listes de tuples (X, y) pour l'entraînement, la validation et le test.\n",
    "    \"\"\"\n",
    "    # Calcul des indices de coupure pour les ensembles de test et de validation\n",
    "    total_size = len(data)\n",
    "    test_cutoff = int(total_size * (1 - test_size))\n",
    "    val_cutoff = int(test_cutoff * (1 - validation_size))\n",
    "\n",
    "    # Initialisation des ensembles\n",
    "    train_data, val_data, test_data = [], [], []\n",
    "\n",
    "    # Créer des fenêtres glissantes pour chaque ensemble\n",
    "    for i in range(max_encoder_length, total_size - max_prediction_length):\n",
    "        # X : Fenêtre d'entrée (backcast)\n",
    "        X = data['value'][i - max_encoder_length:i].values  # Données historiques\n",
    "        # y : Fenêtre de sortie (forecast)\n",
    "        y = data['value'][i:i + max_prediction_length].values  # Valeurs futures à prédire\n",
    "        \n",
    "        # Séparer les données en train, validation et test\n",
    "        if i < val_cutoff:\n",
    "            train_data.append((X, y))\n",
    "        elif i < test_cutoff:\n",
    "            val_data.append((X, y))\n",
    "        else:\n",
    "            test_data.append((X, y))\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Paramètres du modèle\n",
    "max_encoder_length = 60  # Nombre de timesteps pour backcast\n",
    "max_prediction_length = 20  # Nombre de timesteps à prédire (forecast)\n",
    "\n",
    "# Créer le dataset\n",
    "train_data, val_data, test_data = create_dataset(data, max_encoder_length, max_prediction_length)\n",
    "\n",
    "# Exemple d'affichage d'une entrée du dataset\n",
    "print(\"Exemple d'entrée (train_data[0]):\")\n",
    "print(\"X (backcast):\", train_data[0][0])\n",
    "print(\"y (forecast):\", train_data[0][1])\n",
    "print(\"X (backcast2):\", train_data[1][0])\n",
    "print(\"y (forecast2):\", train_data[1][1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_batch shape: torch.Size([64, 60])\n",
      "y_batch shape: torch.Size([64, 20])\n",
      "tensor([0.0497, 0.0861])\n",
      "X_batch shape: torch.Size([64, 60])\n",
      "y_batch shape: torch.Size([64, 20])\n",
      "tensor([0.2042, 0.3571])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Définir un Dataset personnalisé pour les séries temporelles\n",
    "class TimeseriesDataset(Dataset):\n",
    "    def __init__(self, data, max_encoder_length, max_prediction_length):\n",
    "        self.data = data\n",
    "        self.max_encoder_length = max_encoder_length\n",
    "        self.max_prediction_length = max_prediction_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Nombre d'exemples dans le dataset\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Récupérer une entrée et sa cible\n",
    "        X, y = self.data[idx]\n",
    "        X_tensor = torch.tensor(X, dtype=torch.float32) # Ajout d'une dimension pour les canaux\n",
    "        y_tensor = torch.tensor(y, dtype=torch.float32)  # Cible (forecast)\n",
    "        return X_tensor, y_tensor\n",
    "\n",
    "# Créer les datasets pour chaque ensemble\n",
    "train_dataset = TimeseriesDataset(train_data, max_encoder_length, max_prediction_length)\n",
    "val_dataset = TimeseriesDataset(val_data, max_encoder_length, max_prediction_length)\n",
    "test_dataset = TimeseriesDataset(test_data, max_encoder_length, max_prediction_length)\n",
    "\n",
    "# Créer des DataLoaders pour chaque ensemble\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Exemple de ce à quoi ressemble un batch\n",
    "i=0\n",
    "for X_batch, y_batch in train_dataloader:\n",
    "    print(\"X_batch shape:\", X_batch.shape)  # Devrait être [batch_size, max_encoder_length, 1]\n",
    "    print(\"y_batch shape:\", y_batch.shape)  # Devrait être [batch_size, max_prediction_length, 1]\n",
    "    print(X_batch[0][0:2])\n",
    "    i=i+1\n",
    "    if i ==2 : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "knots = torch.tensor([[1.0, 2.0, 3.0], \n",
    "                      [4.0, 5.0, 6.0]])\n",
    "#knots = knots[:,None,:]\n",
    "#knots.size()\n",
    "knots = knots.unsqueeze(1)\n",
    "#knots.size()\n",
    "forecast=F.interpolate(knots, size=6, mode=\"linear\").squeeze(1)\n",
    "#knots.size()\n",
    "\n",
    "print(forecast.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y = torch.tensor([1.0,2,3 ,5,1,7,3,35,4],dtype=float)\n",
    "y = torch.tensor([[1.0, 2.0, 3.0], \n",
    "                      [4.0, 5.0, 6.0]])\n",
    "pooling_layer = nn.MaxPool1d(kernel_size=2, stride=2, ceil_mode=True)\n",
    "\n",
    "pooling_layer(y).size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pool of size=3, stride=2\n",
    "m = nn.MaxPool1d(3, stride=3)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Block(nn.module):\n",
    "    def __init__(self, input_size,horizon, hidden_sizes, kernel_size, expressiveness_ratio,num_layer):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        self.L= input_size\n",
    "        self.H= horizon\n",
    "        self.r_l= expressiveness_ratio\n",
    "        self.k_l= kernel_size\n",
    "        self.num_layer=num_layer\n",
    "        self.kernel_size = kernel_size\n",
    "        self.expressiveness_ratio = expressiveness_ratio\n",
    "        self.theta_size= self._rl * self.H\n",
    "        \n",
    "        # MaxPool layer for multi rate signal sampling\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=self.k_l)\n",
    "        \n",
    "        self.layers = nn.ModuleList() # To handle a list of layers\n",
    "\n",
    "        for hidden_size in hidden_sizes:\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "        \n",
    "        self.linear_f = nn.Linear(hidden_sizes[-1], self.theta_size)\n",
    "        self.linear_b = nn.Linear(hidden_sizes[-1], self.theta_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply max pooling (multi-rate sampling)\n",
    "        x_pooled = self.pool(x)   \n",
    "        h = self.mlp(x_pooled)\n",
    "        theta_f = self.linear_f(h).unsqueeze(1)\n",
    "        theta_b = self.linear_b(h).unsqueeze(1)\n",
    "\n",
    "        forecast= F.interpolate(theta_f, size= self.H, mode=\"linear\")\n",
    "        backcast= F.interpolate(theta_b, size=self.L, mode=\"linear\")\n",
    "        \n",
    "        return forecast, backcast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
